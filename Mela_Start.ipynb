{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1        NaN\n",
       "2        NaN\n",
       "3        NaN\n",
       "4        NaN\n",
       "          ..\n",
       "523487   NaN\n",
       "523488   NaN\n",
       "523489   NaN\n",
       "523490   NaN\n",
       "523491   NaN\n",
       "Name: TUMOR_SIZE, Length: 523492, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mela = pd.read_csv('Melanoma.csv')\n",
    "mela['TUMOR_SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mela = mela.rename(columns={'CS_SITESPECIFIC_FACTOR_1': \"Depth\", 'CS_SITESPECIFIC_FACTOR_2': 'Ulceration',\n",
    "       'CS_SITESPECIFIC_FACTOR_3': 'lymph_node_mets', 'CS_SITESPECIFIC_FACTOR_4': 'LDH'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribs = ['AGE','SEX','Depth', 'Ulceration',\n",
    "       'lymph_node_mets', 'LDH', 'CS_EXTENSION', 'CS_TUMOR_SIZEEXT_EVAL', 'REGIONAL_NODES_POSITIVE', 'REGIONAL_NODES_EXAMINED', 'CS_METS_AT_DX', 'CS_METS_EVAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data \n",
    "\n",
    "We first want to remove data with missing attributes. In the future, we can do some imputing for missing features, but let's first start with the cleanest version of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 523488 entries, 0 to 523491\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   AGE                      523488 non-null  int64  \n",
      " 1   SEX                      523488 non-null  int64  \n",
      " 2   Depth                    523488 non-null  float64\n",
      " 3   Ulceration               523488 non-null  float64\n",
      " 4   lymph_node_mets          523488 non-null  float64\n",
      " 5   LDH                      523488 non-null  float64\n",
      " 6   CS_EXTENSION             523488 non-null  float64\n",
      " 7   CS_TUMOR_SIZEEXT_EVAL    523488 non-null  float64\n",
      " 8   REGIONAL_NODES_POSITIVE  523488 non-null  int64  \n",
      " 9   REGIONAL_NODES_EXAMINED  523488 non-null  int64  \n",
      " 10  CS_METS_AT_DX            523488 non-null  int64  \n",
      " 11  CS_METS_EVAL             523488 non-null  float64\n",
      "dtypes: float64(7), int64(5)\n",
      "memory usage: 51.9 MB\n"
     ]
    }
   ],
   "source": [
    "df = mela[attribs].dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've dropped the rows with missing information, we should also get rid of the rows where the data was unkown (just to start with). Later, we can use interpolation to decide what values to put into these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 175116 entries, 4 to 523488\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   AGE                      175116 non-null  int64  \n",
      " 1   SEX                      175116 non-null  int64  \n",
      " 2   Depth                    175116 non-null  float64\n",
      " 3   Ulceration               175116 non-null  float64\n",
      " 4   lymph_node_mets          175116 non-null  float64\n",
      " 5   LDH                      175116 non-null  float64\n",
      " 6   CS_EXTENSION             175116 non-null  float64\n",
      " 7   CS_TUMOR_SIZEEXT_EVAL    175116 non-null  float64\n",
      " 8   REGIONAL_NODES_POSITIVE  175116 non-null  int64  \n",
      " 9   REGIONAL_NODES_EXAMINED  175116 non-null  int64  \n",
      " 10  CS_METS_AT_DX            175116 non-null  int64  \n",
      " 11  CS_METS_EVAL             175116 non-null  float64\n",
      "dtypes: float64(7), int64(5)\n",
      "memory usage: 17.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 174962 entries, 4 to 523488\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   AGE                      174962 non-null  int64  \n",
      " 1   SEX                      174962 non-null  int64  \n",
      " 2   Depth                    174962 non-null  float64\n",
      " 3   Ulceration               174962 non-null  float64\n",
      " 4   lymph_node_mets          174962 non-null  float64\n",
      " 5   LDH                      174962 non-null  float64\n",
      " 6   CS_EXTENSION             174962 non-null  float64\n",
      " 7   CS_TUMOR_SIZEEXT_EVAL    174962 non-null  float64\n",
      " 8   REGIONAL_NODES_POSITIVE  174962 non-null  int64  \n",
      " 9   REGIONAL_NODES_EXAMINED  174962 non-null  int64  \n",
      " 10  CS_METS_AT_DX            174962 non-null  int64  \n",
      " 11  CS_METS_EVAL             174962 non-null  float64\n",
      "dtypes: float64(7), int64(5)\n",
      "memory usage: 17.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Ulceration</th>\n",
       "      <th>lymph_node_mets</th>\n",
       "      <th>LDH</th>\n",
       "      <th>CS_EXTENSION</th>\n",
       "      <th>CS_TUMOR_SIZEEXT_EVAL</th>\n",
       "      <th>REGIONAL_NODES_POSITIVE</th>\n",
       "      <th>REGIONAL_NODES_EXAMINED</th>\n",
       "      <th>CS_METS_AT_DX</th>\n",
       "      <th>CS_METS_EVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>270.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  SEX  Depth  Ulceration  lymph_node_mets    LDH  CS_EXTENSION  \\\n",
       "4    54    1   42.0         0.0              5.0  998.0         100.0   \n",
       "12   60    1  270.0        10.0              0.0    0.0         300.0   \n",
       "17   60    1  101.0         0.0             43.0  998.0         100.0   \n",
       "30   57    2  100.0         0.0              0.0  998.0         100.0   \n",
       "31   76    1  265.0         0.0              0.0    0.0         300.0   \n",
       "\n",
       "    CS_TUMOR_SIZEEXT_EVAL  REGIONAL_NODES_POSITIVE  REGIONAL_NODES_EXAMINED  \\\n",
       "4                     3.0                       98                        0   \n",
       "12                    3.0                        0                        3   \n",
       "17                    3.0                        1                        3   \n",
       "30                    3.0                        0                        1   \n",
       "31                    3.0                       98                        0   \n",
       "\n",
       "    CS_METS_AT_DX  CS_METS_EVAL  \n",
       "4               0           0.0  \n",
       "12              0           0.0  \n",
       "17              0           0.0  \n",
       "30              0           0.0  \n",
       "31              0           0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[(df != 999).all(1)]\n",
    "new_df.info()\n",
    "\n",
    "new_df = new_df[(new_df['CS_TUMOR_SIZEEXT_EVAL'] != 9)]\n",
    "new_df.info()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the features that have same meaning:\n",
    "Ulceration 10.0 and Ulceration 1.0 both mean the existance of ulceration. We also need to adjust values for LDH, lymph_node_mets, cs_extension, cs_tumor_size_ext_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    145667\n",
       "1.0     29295\n",
       "Name: Ulceration, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Ulceration'] = new_df['Ulceration'].replace(10.0, 1.0)\n",
    "new_df['Ulceration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    166002\n",
       "4.0      6397\n",
       "5.0      1119\n",
       "6.0       323\n",
       "Name: LDH, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['LDH'].value_counts()\n",
    "new_df = new_df[(new_df['LDH'] != 997)]\n",
    "new_df['LDH'].value_counts()\n",
    "new_df['LDH'] = new_df['LDH'].replace(2, 0)\n",
    "new_df['LDH'] = new_df['LDH'].replace(10, 4)\n",
    "new_df['LDH'] = new_df['LDH'].replace(20, 5)\n",
    "new_df['LDH'] = new_df['LDH'].replace(30, 6)\n",
    "new_df['LDH'] = new_df['LDH'].replace(998, 0)\n",
    "new_df = new_df[(new_df['LDH'] != 8)] #info not in charts\n",
    "new_df['LDH'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    156440\n",
       "1.0     11470\n",
       "2.0      5931\n",
       "Name: lymph_node_mets, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['lymph_node_mets'].value_counts()\n",
    "new_df['lymph_node_mets'] = new_df['lymph_node_mets'].replace([10, 20, 5, 43, 45, 48, 50, 100, 150], [1, 2, 0, 2, 2, 2, 2, 2, 2])\n",
    "#maybe not best way to encode this\n",
    "new_df['lymph_node_mets'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 300.0    60355\n",
       " 100.0    42791\n",
       " 200.0    32979\n",
       " 500.0     8924\n",
       " 0.0       7853\n",
       " 400.0     6806\n",
       " 310.0     3913\n",
       " 330.0     1848\n",
       " 315.0     1367\n",
       " 375.0     1067\n",
       "-100.0      967\n",
       " 350.0      834\n",
       " 355.0      695\n",
       " 370.0      601\n",
       " 30.0       484\n",
       " 335.0      463\n",
       " 10.0       344\n",
       " 800.0      343\n",
       " 20.0       276\n",
       " 320.0      232\n",
       " 50.0       176\n",
       " 380.0      140\n",
       " 360.0      122\n",
       " 340.0      110\n",
       " 40.0        65\n",
       " 95.0        37\n",
       " 99.0        32\n",
       " 80.0        17\n",
       "Name: CS_EXTENSION, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['CS_EXTENSION'].value_counts()\n",
    "new_df['CS_EXTENSION'] = new_df['CS_EXTENSION'].replace(950, -100)\n",
    "new_df['CS_EXTENSION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    169636\n",
       "0.0      4205\n",
       "Name: CS_TUMOR_SIZEEXT_EVAL, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['CS_TUMOR_SIZEEXT_EVAL'].value_counts()\n",
    "new_df['CS_TUMOR_SIZEEXT_EVAL'] = new_df['CS_TUMOR_SIZEEXT_EVAL'].replace([1,5,6,2], [0,3,3,3])\n",
    "new_df['CS_TUMOR_SIZEEXT_EVAL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Ulceration</th>\n",
       "      <th>lymph_node_mets</th>\n",
       "      <th>LDH</th>\n",
       "      <th>CS_EXTENSION</th>\n",
       "      <th>CS_TUMOR_SIZEEXT_EVAL</th>\n",
       "      <th>REGIONAL_NODES_POSITIVE</th>\n",
       "      <th>REGIONAL_NODES_EXAMINED</th>\n",
       "      <th>CS_METS_AT_DX</th>\n",
       "      <th>CS_METS_EVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "      <td>173841.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.598006</td>\n",
       "      <td>1.429341</td>\n",
       "      <td>143.320707</td>\n",
       "      <td>0.166997</td>\n",
       "      <td>0.134215</td>\n",
       "      <td>0.190525</td>\n",
       "      <td>231.043787</td>\n",
       "      <td>2.927434</td>\n",
       "      <td>49.033582</td>\n",
       "      <td>3.874707</td>\n",
       "      <td>1.190784</td>\n",
       "      <td>0.065554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.242053</td>\n",
       "      <td>0.494983</td>\n",
       "      <td>192.854659</td>\n",
       "      <td>0.372975</td>\n",
       "      <td>0.429461</td>\n",
       "      <td>0.883337</td>\n",
       "      <td>124.848447</td>\n",
       "      <td>0.460906</td>\n",
       "      <td>48.813561</td>\n",
       "      <td>12.391659</td>\n",
       "      <td>9.264519</td>\n",
       "      <td>0.584816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AGE            SEX          Depth     Ulceration  \\\n",
       "count  173841.000000  173841.000000  173841.000000  173841.000000   \n",
       "mean       60.598006       1.429341     143.320707       0.166997   \n",
       "std        16.242053       0.494983     192.854659       0.372975   \n",
       "min        18.000000       1.000000       0.000000       0.000000   \n",
       "25%        50.000000       1.000000      33.000000       0.000000   \n",
       "50%        62.000000       1.000000      72.000000       0.000000   \n",
       "75%        73.000000       2.000000     161.000000       0.000000   \n",
       "max        90.000000       2.000000     990.000000       1.000000   \n",
       "\n",
       "       lymph_node_mets            LDH   CS_EXTENSION  CS_TUMOR_SIZEEXT_EVAL  \\\n",
       "count    173841.000000  173841.000000  173841.000000          173841.000000   \n",
       "mean          0.134215       0.190525     231.043787               2.927434   \n",
       "std           0.429461       0.883337     124.848447               0.460906   \n",
       "min           0.000000       0.000000    -100.000000               0.000000   \n",
       "25%           0.000000       0.000000     100.000000               3.000000   \n",
       "50%           0.000000       0.000000     300.000000               3.000000   \n",
       "75%           0.000000       0.000000     300.000000               3.000000   \n",
       "max           2.000000       6.000000     800.000000               3.000000   \n",
       "\n",
       "       REGIONAL_NODES_POSITIVE  REGIONAL_NODES_EXAMINED  CS_METS_AT_DX  \\\n",
       "count            173841.000000            173841.000000  173841.000000   \n",
       "mean                 49.033582                 3.874707       1.190784   \n",
       "std                  48.813561                12.391659       9.264519   \n",
       "min                   0.000000                 0.000000       0.000000   \n",
       "25%                   0.000000                 0.000000       0.000000   \n",
       "50%                  13.000000                 1.000000       0.000000   \n",
       "75%                  98.000000                 2.000000       0.000000   \n",
       "max                  99.000000                99.000000      99.000000   \n",
       "\n",
       "        CS_METS_EVAL  \n",
       "count  173841.000000  \n",
       "mean        0.065554  \n",
       "std         0.584816  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         9.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    157098\n",
       "True      16340\n",
       "Name: PERCENT_POS, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['REGIONAL_NODES_POSITIVE'] = new_df['REGIONAL_NODES_POSITIVE'].replace(98, 0)\n",
    "#new_df['REGIONAL_NODES_POSITIVE'].value_counts()\n",
    "new_df = new_df[(new_df['REGIONAL_NODES_POSITIVE'] != 99)]\n",
    "new_df = new_df[(new_df['REGIONAL_NODES_EXAMINED'] != 99)]\n",
    "\n",
    "new_df['REGIONAL_NODES_EXAMINED'].replace(0,1)\n",
    "new_df['PERCENT_POS'] = new_df['REGIONAL_NODES_POSITIVE'] > 0 \n",
    "new_df['PERCENT_POS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into training and test sets\n",
    "\n",
    "The \"percent_pos\" column will be our y_train/y_test values, the rest of the attributes will be our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attribs = ['AGE','SEX','Depth','Ulceration',\n",
    "       'lymph_node_mets', 'LDH', 'CS_EXTENSION', 'CS_TUMOR_SIZEEXT_EVAL']\n",
    "\n",
    "X = new_df[attribs]\n",
    "y = new_df['PERCENT_POS']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(new_df[attribs])\n",
    "X = pd.DataFrame(X, columns=attribs)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Attributes\n",
    "\n",
    "We have a few <b>numerical attributes</b>\n",
    "- Age\n",
    "- Depth\n",
    "- LDH Maybe?\n",
    "- Lymph Node Mets\n",
    "- CS Extension (cardinal)\n",
    "\n",
    "\n",
    "<b>Categorical Attributes</b>\n",
    "- Sex\n",
    "- Ulceration\n",
    "- CS_TUMOR_SIZEEXT_EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.attribute_names]\n",
    "    \n",
    "    \n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X,y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X], index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"select_numeric\", DataFrameSelector([\"AGE\",\"Depth\", \"LDH\", \"lymph_node_mets\", \"CS_EXTENSION\"])),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "     ])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector(['SEX', 'Ulceration', 'CS_TUMOR_SIZEEXT_EVAL'])),\n",
    "    (\"imputer\", MostFrequentImputer()),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PERCENT_POS                1.000000\n",
       "lymph_node_mets            0.837491\n",
       "REGIONAL_NODES_EXAMINED    0.409011\n",
       "Depth                      0.300244\n",
       "REGIONAL_NODES_POSITIVE    0.274160\n",
       "Ulceration                 0.249664\n",
       "CS_EXTENSION               0.225428\n",
       "LDH                        0.080740\n",
       "CS_METS_AT_DX              0.077071\n",
       "CS_METS_EVAL               0.033199\n",
       "CS_TUMOR_SIZEEXT_EVAL     -0.009613\n",
       "SEX                       -0.032846\n",
       "AGE                       -0.056930\n",
       "Name: PERCENT_POS, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = new_df.corr()\n",
    "corr_matrix[\"PERCENT_POS\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34437925, -0.74352332, -0.21567508, -0.31257102, -1.85255714],\n",
       "       [-0.4059391 , -0.73833885, -0.21567508, -0.31257102,  2.15499914],\n",
       "       [-2.31429455, -0.53614457, -0.21567508, -0.31257102, -1.05104588],\n",
       "       ...,\n",
       "       [-0.09813983, -0.09546473, -0.21567508, -0.31257102,  0.55197663],\n",
       "       [-0.4059391 , -0.44282414, -0.21567508, -0.31257102, -1.05104588],\n",
       "       [ 0.70213826,  2.88560477, -0.21567508, -0.31257102,  1.15311007]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num = num_pipeline.fit_transform(X_train)\n",
    "train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('select_cat',\n",
       "                 DataFrameSelector(attribute_names=['SEX', 'Ulceration',\n",
       "                                                    'CS_TUMOR_SIZEEXT_EVAL'])),\n",
       "                ('imputer', MostFrequentImputer()),\n",
       "                ('cat_encoder',\n",
       "                 OneHotEncoder(categories='auto', drop=None,\n",
       "                               dtype=<class 'numpy.float64'>,\n",
       "                               handle_unknown='error', sparse=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(X_train)\n",
    "cat_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34437925, -0.74352332, -0.21567508, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.4059391 , -0.73833885, -0.21567508, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-2.31429455, -0.53614457, -0.21567508, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.09813983, -0.09546473, -0.21567508, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.4059391 , -0.44282414, -0.21567508, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.70213826,  2.88560477, -0.21567508, ...,  1.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline)\n",
    "])\n",
    "\n",
    "X_train = preprocess_pipeline.fit_transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class BaseLine(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905553225724514"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "base_line_clf = BaseLine()\n",
    "base_scores = cross_val_score(base_line_clf,X_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "base_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880209633142002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9880037422607686"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "log_clf.fit(X_train,y_train)\n",
    "log_scores = cross_val_score(log_clf, X_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "y_pred = log_clf.predict(X_train)\n",
    "log_score = accuracy_score(y_train,y_pred)\n",
    "print(log_score)\n",
    "log_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9870883200838648\n",
      "The precision is 0.9083686440677966, the recall is 0.9589934762348555, and the f1 score is 0.9329948318070541\n"
     ]
    }
   ],
   "source": [
    "X_test = preprocess_pipeline.fit_transform(X_test) #running our train_set through the pipeline\n",
    "y_pred = log_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "log_score = accuracy_score(y_test, y_pred)\n",
    "print(log_score)\n",
    "#print(y_test)\n",
    "log_f1 = f1_score(y_test,y_pred)\n",
    "log_recall = recall_score(y_test, y_pred)\n",
    "log_precision = precision_score(y_test,y_pred)\n",
    "print(f\"The precision is {log_precision}, the recall is {log_recall}, and the f1 score is {log_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = log_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99198464 0.00801536]\n",
      " [0.99433901 0.00566099]\n",
      " [0.98934344 0.01065656]\n",
      " ...\n",
      " [0.98796975 0.01203025]\n",
      " [0.99014811 0.00985189]\n",
      " [0.99456198 0.00543802]]\n"
     ]
    }
   ],
   "source": [
    "print(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51351,   519],\n",
       "       [  220,  5145]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5664"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_prob[:,1] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "gnb_score = accuracy_score(y_test, y_pred)\n",
    "print(gnb_score)\n",
    "#print(y_test)\n",
    "gnb_f1 = f1_score(y_test,y_pred)\n",
    "gnb_recall = recall_score(y_test, y_pred)\n",
    "gnb_precision = precision_score(y_test,y_pred)\n",
    "print(f\"The precision is {gnb_precision}, the recall is {gnb_recall}, and the f1 score is {gnb_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "tree_score = accuracy_score(y_test, y_pred)\n",
    "print(tree_score)\n",
    "#print(y_test)\n",
    "tree_f1 = f1_score(y_test,y_pred)\n",
    "tree_recall = recall_score(y_test, y_pred)\n",
    "tree_precision = precision_score(y_test,y_pred)\n",
    "print(f\"The precision is {tree_precision}, the recall is {tree_recall}, and the f1 score is {tree_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_prob[:,1] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_prob[:,0] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
